{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\n",
    "    'dataset.csv',\n",
    "    usecols=['order_id', 'user_id', 'sequence_id', 'skill_id', 'correct'],\n",
    "    encoding='utf-8'\n",
    ").dropna(subset=['skill_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_question = data.skill_id.unique().tolist()\n",
    "num_skill = len(raw_question)\n",
    "\n",
    "# question id from 0 to (num_skill - 1)\n",
    "questions = { p: i for i, p in enumerate(raw_question) }\n",
    "\n",
    "print(\"number of skills: %d\" % num_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_seq(students):\n",
    "    all_sequences = []\n",
    "    for student_id in tqdm.tqdm(students, 'parse student sequence:\\t'):\n",
    "        student_sequence = parse_student_seq(data[data.user_id == student_id])\n",
    "        all_sequences.extend([student_sequence])\n",
    "    return all_sequences\n",
    "\n",
    "\n",
    "def parse_student_seq(student):\n",
    "    seq = student.sort_values('order_id')\n",
    "    q = [questions[q] for q in seq.skill_id.tolist()]\n",
    "    a = seq.correct.tolist()\n",
    "    return q, a\n",
    "\n",
    "\n",
    "# [(question_sequence_0, answer_sequence_0), ..., (question_sequence_n, answer_sequence_n)]\n",
    "sequences = parse_all_seq(data.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size=.7, shuffle=True):\n",
    "    if shuffle:\n",
    "        random.shuffle(data)\n",
    "    boundary = round(len(data) * train_size)\n",
    "    return data[: boundary], data[boundary:]\n",
    "\n",
    "\n",
    "train_sequences, test_sequences = train_test_split(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences2tl(sequences, trgpath):\n",
    "    with open(trgpath, 'a', encoding='utf8') as f:\n",
    "        for seq in tqdm.tqdm(sequences, 'write into file: '):\n",
    "            questions, answers = seq\n",
    "            seq_len = len(questions)\n",
    "            f.write(str(seq_len) + '\\n')\n",
    "            f.write(','.join([str(q) for q in questions]) + '\\n')\n",
    "            f.write(','.join([str(a) for a in answers]) + '\\n')\n",
    "\n",
    "\n",
    "# save triple line format for other tasks\n",
    "sequences2tl(train_sequences, 'train.txt')\n",
    "sequences2tl(test_sequences, 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_STEP = 50\n",
    "NUM_QUESTIONS = num_skill\n",
    "\n",
    "# def encode_onehot(sequences, max_step, num_questions):\n",
    "#     result = []\n",
    "\n",
    "#     for q, a in tqdm.tqdm(sequences, 'convert to one-hot format: '):\n",
    "#         length = len(q)\n",
    "#         # append questions' and answers' length to an integer multiple of max_step\n",
    "#         mod = 0 if length % max_step == 0 else (max_step - length % max_step)\n",
    "#         onehot = np.zeros(shape=[length + mod, 2 * num_questions])\n",
    "#         for i, q_id in enumerate(q):\n",
    "#             index = int(q_id if a[i] > 0 else q_id + num_questions)\n",
    "#             onehot[i][index] = 1\n",
    "#         result = np.append(result, onehot)\n",
    "    \n",
    "#     return result.reshape(-1, max_step, 2 * num_questions)\n",
    "\n",
    "\n",
    "def encode_onehot(sequences, max_step, num_questions):\n",
    "    # Calculate the number of chunks (each of size max_step)\n",
    "    chunks_per_seq = [max(1, (len(q) + max_step - 1) // max_step) for q, a in sequences]\n",
    "    total_chunks = sum(chunks_per_seq)\n",
    "    \n",
    "    # Pre-allocate the result array\n",
    "    result = np.zeros((total_chunks * max_step, 2 * num_questions))\n",
    "    \n",
    "    chunk_idx = 0\n",
    "    for seq_idx, (q, a) in enumerate(tqdm.tqdm(sequences, 'convert to one-hot format: ')):\n",
    "        \n",
    "        # Fill in the onehot values\n",
    "        for i, q_id in enumerate(q):\n",
    "            index = int(q_id if a[i] > 0 else q_id + num_questions)\n",
    "            result_idx = chunk_idx * max_step + i\n",
    "            result[result_idx, index] = 1\n",
    "        \n",
    "        chunk_idx += chunks_per_seq[seq_idx]\n",
    "    \n",
    "    return result.reshape(-1, max_step, 2 * num_questions)\n",
    "\n",
    "train_data = encode_onehot(train_sequences, MAX_STEP, NUM_QUESTIONS)\n",
    "test_data = encode_onehot(test_sequences, MAX_STEP, NUM_QUESTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train data shape: \", train_data.shape)\n",
    "print(\"test data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save onehot data\n",
    "np.save('train_data.npy', train_data)\n",
    "np.save('test_data.npy', test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql_task_adaptation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
