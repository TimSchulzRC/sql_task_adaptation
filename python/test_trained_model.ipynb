{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.contrib import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_COUNT = 50\n",
    "LEARNER_COUNT = 10000\n",
    "SIM_PARAM_COMPLEXITY_CONVERGATION_FACTOR = 0.5\n",
    "SIM_PARAM_SCAFFOLDING_BONUS_DISTRIBUTION = (0.1, 0.002, 0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbeta(n: int, mean: float, var: float, min: float = 0, max: float = 1) -> float:\n",
    "    dmin = mean - min\n",
    "    dmax = max - mean\n",
    "\n",
    "    if dmin <= 0 or dmax <= 0:\n",
    "        raise ValueError(f\"mean must be between min = {min} and max = {max}\")\n",
    "\n",
    "    if var >= dmin * dmax:\n",
    "        raise ValueError(\n",
    "            f\"var must be less than (mean - min) * (max - mean) = {dmin * dmax}\")\n",
    "\n",
    "    mx = (mean - min) / (max - min)\n",
    "    vx = var / (max - min) ** 2\n",
    "\n",
    "    a = ((1 - mx) / vx - 1 / mx) * mx ** 2\n",
    "    b = a * (1 / mx - 1)\n",
    "\n",
    "    x = np.random.beta(a, b, n)\n",
    "    y = (max - min) * x + min\n",
    "\n",
    "    return y.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_complexity(frequency, regulation=0.5, weight=1):\n",
    "    return ((frequency*weight)**(1/regulation))/(1+((frequency*weight)**(1/regulation))) \n",
    "\n",
    "def calc_frequency(complexity, regulation=0.5, weight=1):\n",
    "    x = -complexity/(1-complexity)\n",
    "    if(x<0): x = x*-1\n",
    "    return x**regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimal_task(dql_model: dict[str, list[str]], learner_competency: dict[str, list[float]], scaffolding_bonus: dict[str, list[float]]):\n",
    "    return {key: [np.clip(calc_frequency(learner_competency[key][i] + scaffolding_bonus[key][i]), 0, 7) for i in range(len(dql_model[key]))] for key in dql_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EduKTM import DKT\n",
    "\n",
    "NUM_QUESTIONS = 9\n",
    "HIDDEN_SIZE = 10\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "dkt = DKT(NUM_QUESTIONS, HIDDEN_SIZE, NUM_LAYERS)\n",
    "dkt.load(\"dkt.params\")\n",
    "model = dkt.dkt_model\n",
    "model.eval()\n",
    "\n",
    "def create_task_with_kt_model(prev_tasks, prev_deltas):\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_task_complexities(task: dict[str, list[int]]):\n",
    "    return {key: calc_complexity_for_category(category) for key, category in task.items()}\n",
    "\n",
    "\n",
    "def calc_complexity_for_category(category: list[int]):\n",
    "    return list(calc_complexity(frequency, regulation=0.5, weight=1) for frequency in category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_scaffolded_competence_bonuses(dql_model: dict[str, list[str]]):\n",
    "    return {key: rgbeta(len(dql_model[key]), *SIM_PARAM_SCAFFOLDING_BONUS_DISTRIBUTION) for key in dql_model}\n",
    "\n",
    "\n",
    "def sample_from_snd_vectorized_and_normalize(X: list[float], mean=0, sd=1):\n",
    "    # Generate random normal samples and normalize using min-max\n",
    "    samples = np.random.normal(mean, sd, len(X))\n",
    "    min_x = min(samples)\n",
    "    max_x = max(samples)\n",
    "    return ((samples - min_x) / (max_x - min_x)).tolist()\n",
    "\n",
    "\n",
    "def create_learner_competencies(dql_model: dict[str, list[str]]):\n",
    "    return {key: sample_from_snd_vectorized_and_normalize(dql_model[key]) for key in dql_model}\n",
    "\n",
    "\n",
    "def create_learner_population(learner_count: int, task_count: int, dql_model: dict[str, list[str]]):\n",
    "    return {\n",
    "        \"learner_competencies\": [create_learner_competencies(dql_model) for _ in range(learner_count)],\n",
    "        \"scaffolding_competence_bonus_per_step_and_learner\": [[create_learner_scaffolded_competence_bonuses(dql_model) for _ in range(learner_count)] for _ in range(task_count)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_population(learner_count: int, task_count: int, dql_model: dict[str, list[str]]):\n",
    "    return {\n",
    "        \"learner_competencies\": [create_learner_competencies(dql_model) for _ in range(learner_count)],\n",
    "        \"scaffolding_competence_bonus_per_step_and_learner\": [[create_learner_scaffolded_competence_bonuses(dql_model) for _ in range(learner_count)] for _ in range(task_count)]\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_delta(learner_competency: dict[str, list[str]], task_complexities: dict[str, list[str]], scaffolding_bonus: dict[str, list[str]]):\n",
    "    result = {}\n",
    "    for key in learner_competency:\n",
    "        result[key] = []\n",
    "        for i in range(len(learner_competency[key])):\n",
    "            k = learner_competency[key][i]\n",
    "            c = task_complexities[key][i]\n",
    "            t = scaffolding_bonus[key][i]\n",
    "            if (c <= k or c > k + t):\n",
    "                result[key].append(0)\n",
    "            else:\n",
    "                result[key].append(c - k)\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_delta_to_competency(competency: dict[str, list[str]], delta: dict[str, list[str]]):\n",
    "    return {key: [competency[key][i] + delta[key][i] for i in range(len(competency[key]))] for key in competency}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_task_adaptation(task_count: int, learner_count: int, dql_model: dict[str, list[str]]):\n",
    "\n",
    "    learner_population = create_learner_population(\n",
    "        learner_count, task_count, dql_model)\n",
    "\n",
    "    simulationLog = [{\n",
    "        \"tasks\": [],\n",
    "        \"competencies\": [],\n",
    "        \"scaffolding_bonuses\": [],\n",
    "        \"deltas\": []\n",
    "    } for _ in range(learner_count)]\n",
    "\n",
    "    for i, j in itertools.product(range(task_count), range(learner_count)):\n",
    "        learner_competency = learner_population[\"learner_competencies\"][j]\n",
    "        scaffolding_bonus = learner_population[\"scaffolding_competence_bonus_per_step_and_learner\"][i][j]\n",
    "        prev_tasks = simulationLog[j][\"tasks\"]\n",
    "        prev_deltas = simulationLog[j][\"deltas\"]\n",
    "        \n",
    "        # task = create_random_task(dql_model)\n",
    "        task = create_optimal_task(\n",
    "            dql_model, learner_competency, scaffolding_bonus)\n",
    "\n",
    "        task_complexities = calc_task_complexities(task)\n",
    "        delta = calculate_delta(\n",
    "            learner_competency, task_complexities, scaffolding_bonus)\n",
    "\n",
    "        # update the learner competency in the global learner population\n",
    "        learner_population[\"learner_competencies\"][j] = add_delta_to_competency(\n",
    "            learner_competency, delta)\n",
    "\n",
    "        simulationLog[j][\"tasks\"].append(task)\n",
    "        simulationLog[j][\"competencies\"].append(learner_competency)\n",
    "        simulationLog[j][\"scaffolding_bonuses\"].append(scaffolding_bonus)\n",
    "        simulationLog[j][\"deltas\"].append(delta)\n",
    "\n",
    "    return simulationLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dql_model = {\n",
    "    \"join\": [\"inner_join\", \"outer_join\", \"self_join\"],\n",
    "    \"nesting\": [\"cte\", \"correlated_subquery\", \"uncorrelated_subquery\"],\n",
    "    \"predicates\": [\"basic_operators\", \"logical_operators\", \"set_operators\"]\n",
    "}\n",
    "\n",
    "\n",
    "simulationLog = simulate_task_adaptation(\n",
    "    TASK_COUNT, LEARNER_COUNT, dql_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simulation_log(simulationLog: dict[str, list[list[float]]], dql_model: dict[str, list[str]], learnerId: int):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "    for i, key in enumerate(dql_model):\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        aggregated_competency_values = []\n",
    "        aggregated_task_values = []\n",
    "        aggregated_competency_plus_bonus_values = []\n",
    "        for i in range(TASK_COUNT):\n",
    "            # Get competency value\n",
    "            competency_values = simulationLog[learnerId][\"competencies\"][i][key]\n",
    "            competency_aggregated = sum(\n",
    "                competency_values)/len(competency_values)\n",
    "            aggregated_competency_values.append(competency_aggregated)\n",
    "\n",
    "            # Get task complexity value\n",
    "            task_values = calc_task_complexities(\n",
    "                simulationLog[learnerId][\"tasks\"][i])[key]\n",
    "            task_aggregated = sum(task_values)/len(task_values)\n",
    "            aggregated_task_values.append(task_aggregated)\n",
    "\n",
    "            scaffolding_bonus_values = simulationLog[learnerId][\"scaffolding_bonuses\"][i][key]\n",
    "            # Add the scaffolding bonus to the competency value\n",
    "            competency_plus_bonus_values = [\n",
    "                a + b for a, b in zip(scaffolding_bonus_values, competency_values)]\n",
    "            competency_plus_bonus_aggregated = sum(\n",
    "                competency_plus_bonus_values)/len(competency_plus_bonus_values)\n",
    "            aggregated_competency_plus_bonus_values.append(\n",
    "                competency_plus_bonus_aggregated)\n",
    "\n",
    "        plt.plot(range(TASK_COUNT), aggregated_competency_values,\n",
    "                 color=color, label=f'{key} competency')\n",
    "        plt.plot(range(TASK_COUNT), aggregated_task_values,\n",
    "                 '.', color=color, label=f'{key} task')\n",
    "        plt.plot(range(TASK_COUNT), aggregated_competency_plus_bonus_values,\n",
    "                 '--', color=color, label=f'{key} competency + scaffolding bonus')\n",
    "\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(0, TASK_COUNT-1)\n",
    "    plt.ylabel(\"Competency\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f\"sql_task_adaptation_{learnerId}.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation_log(simulationLog, dql_model, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql_task_adaptation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
