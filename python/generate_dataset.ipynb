{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.contrib import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_COUNT = 50\n",
    "LEARNER_COUNT = 10000\n",
    "SIM_PARAM_COMPLEXITY_CONVERGATION_FACTOR = 0.5\n",
    "SIM_PARAM_SCAFFOLDING_BONUS_DISTRIBUTION = (0.1, 0.002, 0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbeta(n: int, mean: float, var: float, min: float = 0, max: float = 1) -> float:\n",
    "    dmin = mean - min\n",
    "    dmax = max - mean\n",
    "\n",
    "    if dmin <= 0 or dmax <= 0:\n",
    "        raise ValueError(f\"mean must be between min = {min} and max = {max}\")\n",
    "\n",
    "    if var >= dmin * dmax:\n",
    "        raise ValueError(\n",
    "            f\"var must be less than (mean - min) * (max - mean) = {dmin * dmax}\")\n",
    "\n",
    "    mx = (mean - min) / (max - min)\n",
    "    vx = var / (max - min) ** 2\n",
    "\n",
    "    a = ((1 - mx) / vx - 1 / mx) * mx ** 2\n",
    "    b = a * (1 / mx - 1)\n",
    "\n",
    "    x = np.random.beta(a, b, n)\n",
    "    y = (max - min) * x + min\n",
    "\n",
    "    return y.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_complexity(frequency, regulation=0.5, weight=1):\n",
    "    return ((frequency*weight)**(1/regulation))/(1+((frequency*weight)**(1/regulation))) \n",
    "\n",
    "def calc_frequency(complexity, regulation=0.5, weight=1):\n",
    "    x = -complexity/(1-complexity)\n",
    "    if(x<0): x = x*-1\n",
    "    return x**regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_task(dql_model: dict[str, list[str]]):\n",
    "    return {key: [random.randint(0, 7) for _ in dql_model[key]] for key in dql_model}\n",
    "\n",
    "\n",
    "def create_optimal_task(dql_model: dict[str, list[str]], learner_competency: dict[str, list[float]], scaffolding_bonus: dict[str, list[float]]):\n",
    "    return {key: [np.clip(calc_frequency(learner_competency[key][i] + scaffolding_bonus[key][i]), 0, 7) for i in range(len(dql_model[key]))] for key in dql_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_task_complexities(task: dict[str, list[int]]):\n",
    "    return {key: calc_complexity_for_category(category) for key, category in task.items()}\n",
    "\n",
    "\n",
    "def calc_complexity_for_category(category: list[int]):\n",
    "    return list(calc_complexity(frequency, regulation=0.5, weight=1) for frequency in category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_scaffolded_competence_bonuses(dql_model: dict[str, list[str]]):\n",
    "    return {key: rgbeta(len(dql_model[key]), *SIM_PARAM_SCAFFOLDING_BONUS_DISTRIBUTION) for key in dql_model}\n",
    "\n",
    "\n",
    "def sample_from_snd_vectorized_and_normalize(X: list[float], mean=0, sd=1):\n",
    "    # Generate random normal samples and normalize using min-max\n",
    "    samples = np.random.normal(mean, sd, len(X))\n",
    "    min_x = min(samples)\n",
    "    max_x = max(samples)\n",
    "    return ((samples - min_x) / (max_x - min_x)).tolist()\n",
    "\n",
    "\n",
    "def create_learner_competencies(dql_model: dict[str, list[str]]):\n",
    "    return {key: sample_from_snd_vectorized_and_normalize(dql_model[key]) for key in dql_model}\n",
    "\n",
    "\n",
    "def create_learner_population(learner_count: int, task_count: int, dql_model: dict[str, list[str]]):\n",
    "    return {\n",
    "        \"learner_competencies\": [create_learner_competencies(dql_model) for _ in range(learner_count)],\n",
    "        \"scaffolding_competence_bonus_per_step_and_learner\": [[create_learner_scaffolded_competence_bonuses(dql_model) for _ in range(learner_count)] for _ in range(task_count)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_population(learner_count: int, task_count: int, dql_model: dict[str, list[str]]):\n",
    "    return {\n",
    "        \"learner_competencies\": [create_learner_competencies(dql_model) for _ in range(learner_count)],\n",
    "        \"scaffolding_competence_bonus_per_step_and_learner\": [[create_learner_scaffolded_competence_bonuses(dql_model) for _ in range(learner_count)] for _ in range(task_count)]\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_delta(learner_competency: dict[str, list[str]], task_complexities: dict[str, list[str]], scaffolding_bonus: dict[str, list[str]]):\n",
    "    result = {}\n",
    "    for key in learner_competency:\n",
    "        result[key] = []\n",
    "        for i in range(len(learner_competency[key])):\n",
    "            k = learner_competency[key][i]\n",
    "            c = task_complexities[key][i]\n",
    "            t = scaffolding_bonus[key][i]\n",
    "            if (c <= k or c > k + t):\n",
    "                result[key].append(0)\n",
    "            else:\n",
    "                result[key].append(c - k)\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_delta_to_competency(competency: dict[str, list[str]], delta: dict[str, list[str]]):\n",
    "    return {key: [competency[key][i] + delta[key][i] for i in range(len(competency[key]))] for key in competency}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_task_adaptation(task_count: int, learner_count: int, dql_model: dict[str, list[str]]):\n",
    "\n",
    "    learner_population = create_learner_population(\n",
    "        learner_count, task_count, dql_model)\n",
    "\n",
    "    simulationLog = [{\n",
    "        \"tasks\": [],\n",
    "        \"competencies\": [],\n",
    "        \"scaffolding_bonuses\": [],\n",
    "        \"deltas\": []\n",
    "    } for _ in range(learner_count)]\n",
    "\n",
    "    for i, j in itertools.product(range(task_count), range(learner_count)):\n",
    "        learner_competency = learner_population[\"learner_competencies\"][j]\n",
    "        scaffolding_bonus = learner_population[\"scaffolding_competence_bonus_per_step_and_learner\"][i][j]\n",
    "\n",
    "        # task = create_random_task(dql_model)\n",
    "        task = create_optimal_task(\n",
    "            dql_model, learner_competency, scaffolding_bonus)\n",
    "\n",
    "        task_complexities = calc_task_complexities(task)\n",
    "        delta = calculate_delta(\n",
    "            learner_competency, task_complexities, scaffolding_bonus)\n",
    "\n",
    "        # update the learner competency in the global learner population\n",
    "        learner_population[\"learner_competencies\"][j] = add_delta_to_competency(\n",
    "            learner_competency, delta)\n",
    "\n",
    "        simulationLog[j][\"tasks\"].append(task)\n",
    "        simulationLog[j][\"competencies\"].append(learner_competency)\n",
    "        simulationLog[j][\"scaffolding_bonuses\"].append(scaffolding_bonus)\n",
    "        simulationLog[j][\"deltas\"].append(delta)\n",
    "\n",
    "    return simulationLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244f655df330479c87de8a1e3732197d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dql_model = {\n",
    "    \"join\": [\"inner_join\", \"outer_join\", \"self_join\"],\n",
    "    \"nesting\": [\"cte\", \"correlated_subquery\", \"uncorrelated_subquery\"],\n",
    "    \"predicates\": [\"basic_operators\", \"logical_operators\", \"set_operators\"]\n",
    "}\n",
    "\n",
    "\n",
    "simulationLog = simulate_task_adaptation(\n",
    "    TASK_COUNT, LEARNER_COUNT, dql_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbe0aaa76904cf58f79773e0ad2ffd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "order_id = 0\n",
    "\n",
    "# Iterate through each student \n",
    "for studentId, taskIndex in itertools.product(range(len(simulationLog)), range(TASK_COUNT)):\n",
    "    task_order_id = order_id  # Create one order_id per task\n",
    "    # Iterate through categories\n",
    "    for category_i, (category_name, category_elements) in enumerate(dql_model.items()):\n",
    "        # Iterate through elements in category\n",
    "        for element_i, element in enumerate(category_elements):\n",
    "            # Get delta for this element\n",
    "            delta = simulationLog[studentId][\"deltas\"][taskIndex][category_name][element_i]\n",
    "            \n",
    "            # Create record with zero-padded IDs\n",
    "            # Calculate position: (category_i * elements_per_category) + element_i\n",
    "            skill_position = (category_i * len(category_elements)) + element_i\n",
    "            record = {\n",
    "                'order_id': f'{task_order_id+1:08d}',\n",
    "                'user_id': f'{studentId+1:06d}',\n",
    "                'sequence_id': f'{studentId+1:06d}',\n",
    "                'skill_id': skill_position+1,\n",
    "                'correct': 1 if delta > 0 else 0\n",
    "            }\n",
    "            records.append(record)\n",
    "    order_id += 1  # Increment order_id only after all records for a task are created\n",
    "\n",
    "# Create and save dataframe\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv('dataset.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql_task_adaptation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
